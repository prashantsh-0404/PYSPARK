{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d66ad3ce-8640-41d7-aa56-872538d525e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01a7803c-078e-4ea9-9ddf-40dde163d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions, Row\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b47ef06-e256-473d-b818-07a18834d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"Operations\").setMaster(\"local[10]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3a2633-8a4b-413f-8a75-c3672805ade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/19 17:11:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2aa4d264-d459-4214-9e62-600e1343ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"../Datasets/WineDataset.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ab15f6e-61ce-4ad9-879d-e9116cc9efb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33725eaa-f2de-416a-bb18-2ef6c7eec505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97588603-5098-4bf5-b873-bf73ee4739c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.repartition(\"Region\",\"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b41dd91a-56cb-4a46-a873-4147a738a91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba2b43a0-faf4-4b0f-84e1-c0a3028b9b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.write.mode(\"overwrite\").partitionBy(\"Country\").csv(\"../Datasets/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "805226e2-2104-4ecf-addd-418b6aa62a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrameWriter.bucketBy() missing 1 required positional argument: 'col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucketBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRegion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: DataFrameWriter.bucketBy() missing 1 required positional argument: 'col'"
     ]
    }
   ],
   "source": [
    "df2.write.bucketBy(col(\"Region\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f8171-e815-47b7-917e-37d5248452a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
